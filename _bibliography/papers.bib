---
---

@inproceedings{NEURIPS2023_b0ca7175,
 author = {Chiappa, Alberto Silvio and Marin Vargas, Alessandro and Huang, Ann and Mathis, Alexander},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {56508--56530},
 publisher = {Curran Associates, Inc.},
 title = {Latent exploration for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/b0ca717599b7ba84d5e4f4c8b1ef6657-Paper-Conference.pdf},
 volume = {36},
 year = {2023},
 preview={lattice.png}
}

@inproceedings{huang2024learningdynamics,
  author       = {Huang, Ann and Singh, Satpreet Harcharan and Rajan, Kanaka},
  title        = {Learning Dynamics and the Geometry of Neural Dynamics in Recurrent Neural Controllers},
  booktitle    = {InterpPol @ RLC 2024 Workshop},
  year         = {2024},
  url          = {https://openreview.net/forum?id=SbbpTtB6B4}
}


@inproceedings{huang2025measuringcontrollingsolutiondegeneracy,
      title={Measuring and Controlling Solution Degeneracy across Task-Trained Recurrent Neural Networks}, 
      author={Ann Huang and Satpreet H. Singh and Flavio Martinelli and Kanaka Rajan},
      booktitle = {Advances in Neural Information Processing Systems},
      year={2025},
      eprint={2410.03972},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.03972}, 
      preview={degeneracy.png},
      selected = {true}
}

@article{huang2025inputDSA,
  author  = {Huang*, Ann and Ostrow*, Mitchell and Singh, Satpreet H. and Kozachkov, Leo and Fiete, Ila and Rajan, Kanaka},
  title   = {InputDSA: Demixing, then comparing recurrent and externally driven dynamics},
  journal = {arXiv},
  year    = {2025},
  selected = {true},
  preview={inputdsa.png}
}


@article {Lachi2024.08.07.606541,
	author = {Lachi*, Divyansha and Huang*, Ann and Mavor-Parker, Augustine N. and Ghosh, Arna and Richards, Blake and Zador, Anthony},
	title = {Stochastic Wiring of Cell Types Enhances Fitness by Generating Phenotypic Variability},
	elocation-id = {2024.08.07.606541},
	year = {2024},
	doi = {10.1101/2024.08.07.606541},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {The development of neural connectivity is a crucial biological process that gives rise to diverse brain circuits and behaviors. Neural development is a stochastic process, but this stochasticity is often treated as a nuisance to overcome rather than as a functional advantage. Here we use a computational model, in which connection probabilities between discrete cell types are genetically specified, to investigate the benefits of stochasticity in the development of neural wiring. We show that this model can be viewed as a generalization of a powerful class of artificial neural networks{\textemdash}Bayesian neural networks{\textemdash}where each network parameter is a sample from a distribution. Our results reveal that stochasticity confers a greater benefit in large networks and variable environments, which may explain its role in organisms with larger brains. Surprisingly, we find that the average fitness over a population of agents is higher than a single agent defined by the average connection probability. Our model reveals how developmental stochasticity, by inducing a form of non-heritable phenotypic variability, can increase the probability that at least some individuals will survive in rapidly changing, unpredictable environments. Our results suggest how stochasticity may be an important feature rather than a bug in neural development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2024/08/08/2024.08.07.606541},
	eprint = {https://www.biorxiv.org/content/early/2024/08/08/2024.08.07.606541.full.pdf},
	journal = {bioRxiv}
}

@article{lin2023temporalencoding,
  author = {Lin, Dongyan and Huang, Ann and Richards, Blake Aaron},
  title = {Temporal encoding in deep reinforcement learning agents},
  journal = {Scientific Reports},
  year = {2023},
  volume = {13},
  number = {1},
  pages = {22335},
  doi = {10.1038/s41598-023-49847-y},
  url = {https://www.nature.com/articles/s41598-023-49847-y},
  preview={timecell.png}
}

@article{LAI2025106201,
title = {Action chunking as conditional policy compression},
journal = {Cognition},
volume = {264},
pages = {106201},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2025.106201},
url = {https://www.sciencedirect.com/science/article/pii/S0010027725001416},
author = {Lucy Lai* and Ann Huang* and Samuel J. Gershman},
keywords = {Action selection, Chunking, Reinforcement learning, Resource rationality, Decision making, Information bottleneck},
preview={chunking.png},
abstract = {Many skills in our everyday lives are learned by sequencing actions towards a desired goal. The action sequence can become a “chunk” when individual actions are grouped together and executed as one unit, making them more efficient to store and execute. While chunking has been studied extensively across various domains, a puzzle remains as to why and under what conditions action chunking occurs. To tackle these questions, we develop a model of conditional policy compression—the reduction in cognitive cost by conditioning on an additional source of information—to explain the origin of chunking. We argue that chunking is a result of optimizing the trade-off between reward and conditional policy complexity. Chunking compresses policies when there is temporal structure in the environment that can be leveraged for action selection, reducing the amount of memory necessary to encode the policy. We experimentally confirm our model’s predictions, showing that chunking reduces conditional policy complexity and reaction times. Chunking also increases with working memory load, consistent with the hypothesis that the degree of policy compression scales with the scarcity of cognitive resources. Finally, chunking also reduces overall working memory load, freeing cognitive resources for the benefit of other, not-chunked information.}
}